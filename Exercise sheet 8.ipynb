{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5547c0f3",
   "metadata": {},
   "source": [
    "# Exercise 1 - Calculate $\\pi$\n",
    "\n",
    "Using the **DSMC method**, calculate the value of **$\\pi$**.\n",
    "\n",
    "\n",
    "**Approach:**\n",
    "In order to do this, create a 2-dimensional domain (defined by the coordinates $x_{min}, x_{max}, y_{min}, y_{max}$) and launch a number P of particles at random locations within. Check which particles lie inside a circle with radius $$ \\frac{x_{max}-x_{min}}{2}, $$ where $x_{min}, x_{max}$ are the x-limits of your 2D domain. \n",
    "\n",
    "Get your value for $\\pi$ by using the following formula:\n",
    "$$\\pi = \\frac{4 \\cdot n_{inside}}{P},$$ where $n_{inside}$ is the number of particles inside the circle and $P$ is the total number of particles.\n",
    "\n",
    "**a)** Play around with the number of particles and plot your calculated value as a function of this number. \n",
    "\n",
    "**b)** Also plot the difference between the value you obtained for $\\pi$ and the real one (as a function of P). \n",
    "\n",
    "**c)** Make a plot for your domain, highlighting the particles that are inside the circle."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa79a24c",
   "metadata": {},
   "source": [
    "# Exercise 2 - Metropolis-Hastings\n",
    "\n",
    "Using the Metropolis-Hastings algorithm, find the standard deviation $\\sigma$ and mean value $\\mu$ of a random Gaussian distribution. The data to be used for this exercise can be found in the file \"input_data.txt\".\n",
    "\n",
    "**Approach (i.e. how the Metropolis-Hastings algorithm looks like):** Start with an initial guess for your standard deviation and mean (you can use the built-in numpy functions for this). \n",
    "\n",
    "Generate new values by adding some random noise to the previous/initial guess. Get the noise from a probability distribution. Use for example a Gaussian distribution which you can get via the function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e4b75c6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from scipy.stats import norm\n",
    "norm(parameter, sigma_m).rvs()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87204e78",
   "metadata": {},
   "source": [
    "from the scipy.stats package, where $sigma_m$ is the average step size. One can assume a value of 0.1 for this, or play around with this parameter and see what happens. Make sure your sigma isn't lower than zero, otherwise you will end up with NaNs or other weird values.\n",
    "\n",
    "Compute the likelihood of your new values. Remember the likelihood formula from the lecture and apply it to your points. Compare the likelihood of the new and old values and accept the most relevant value. \n",
    "\n",
    "**Note:** Should the likelihood of your new value be lower than the older one, you can use the _acceptance-rejection criterion_ to determine which one to keep (see lecture slides and use a random _r_ value between 0 and 1).\n",
    "\n",
    "Repeat until you converge on a value (ideally the same one as the values computed with the built-in functions).\n",
    "\n",
    "For the following plots make sure to include the true values as well, i.e. overplot $\\sigma$ and $\\mu$ where relevant.\n",
    "\n",
    "**a)** Plot $\\mu$ as a function of the number of iterations.\n",
    "\n",
    "**b)** Plot $\\sigma$ as a function of the number of iterations.\n",
    "\n",
    "**c)** Make a plot of the dataset you were given and overplot your best fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a374bc7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
